--- 
title: "Research on Charging Facility Distribution in London"
author: "Anni Huo"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
---

# Data Source

## NCR dataset

Accessing and adding data on the National ChargePoint Registry (NCR) on public electric vehicle ChargePoint in the UK (.csv):
https://www.gov.uk/guidance/find-and-use-data-on-public-electric-vehicle-chargepoints#accessing-data-on-ncr

The NCR is a database of publicly-available chargepoints for electric vehicles in the UK established in 2011. Whilst the database is freely open to all who wish to use the database, the main data users are business data users for their products (e.g. smartphone apps, satellite navigation and route planning).


 NCR content 

	
	▪ registry - Charge Point Registry
	
	▪ type - Connector Types
	
	▪ bearing - Bearings
	
	▪ method - Charging Methods
	
	▪ mode - Charge Modes
	
	▪ status - Connector Statuses
	
	
## Ward Profiles and Atlas (2015)

Greater London Authority (GLA)
website:https://data.london.gov.uk/dataset/ward-profiles-and-atlas

The ward profiles and ward atlas provide a range of demographic and related data for each ward in Greater London. They are designed to provide an overview of the population in these small areas by presenting a range of data on the population, diversity, households, life expectancy, housing, crime, benefits, land use, deprivation, and employment.

 Ward profile content 

  ▪ population density
	
	▪ car use
	
	▪ employment and economic activity
	
	▪ average house prices
	
	▪ road casualties
	
	▪ public transport accessibility (PTALs)



## Households of London Wards

Provide the dataset involving total number of households by wards in London
website:https://data.london.gov.uk/dataset/households-household-type-2001-ward


## Shape file of the major road network

Local authority traffic figures give the total volume of traffic across each local authority for the whole year. 
Parking data is contained in the dataset
website:https://roadtraffic.dft.gov.uk/downloads

## Land Use by Borough and Ward


Land Use Statistics by ward (Generalised Land Use Database) 2005 (Enhanced Base map). Uses include, domestic buildings, gardens, non-domestic buildings, greenspace, paths, rail, road and water. Area is presented in Thousands of square metres ('000s m2). These are experimental Statistics - this information has been developed in accordance with the principles set out in the National Statistics Code of Practice but has yet to be fully accredited as a National Statistic.

website:https://data.london.gov.uk/dataset/land-use-ward

 Land use dataset content 

  ▪ persentage of residential area
	
	▪ persentage of road area
	
	▪ persentage of rail area
	


<!--chapter:end:index.Rmd-->


# Descriptive Analysis

## Load packages


### Load basic package

```{r}
library(sp)
library(sf)
library(rgeos)
library(tmap)
library(tmaptools)
library(maptools)
library(tidyverse)
library(spdep)
library(janitor)
library(rgdal)
```

### Load plot library

```{r}
library(ggplot2)
library(RColorBrewer)
```




## Load data


### Load charge point registry.csv file


```{r}
charge <- read_csv("datasets/national-charge-point-registry.csv")
summary(charge$chargeDeviceStatus)
```


### Load London wards shapefile

```{r}
londonwards <- st_read("datasets/wards/London_Ward_CityMerged.shp") %>% 
  st_transform(., 27700)
```




## Filter data



```{r}
chargepoints <- charge [charge$chargeDeviceStatus=="In service" & !is.na(charge$latitude) & !is.na(charge$longitude),] 
```


### Function to filter year (2014, 2017, 2020 register)

```{r}
filterfun <- function(end){
  enddate <- end
  
  filterpoints <- chargepoints %>% 
    filter(chargepoints$dateCreated<=enddate)
  return(filterpoints)
}

```


### Function to transform projection & crop to London

```{r}
londonPfun <- function(end){
  filteredpoints <- filterfun(end)
  transpoints <- filteredpoints %>% 
    select(., c(3,4,5)) %>% 
    st_as_sf(., coords = c("longitude", "latitude"),crs = 4326) %>% 
    st_transform(., 27700) %>%
    distinct()
  
  charge_london <- st_intersects(londonwards, transpoints)
  londonpoints <- transpoints[unlist(charge_london),]
  return(londonpoints)
}
```


### Instance object


```{r}
trend <- data.frame(date=c("2012", "2013", "2014", "2015", "2016",
                           "2017", "2018", "2019", "2020"),
                    count=c(nrow(londonPfun("2012-12-31")),nrow(londonPfun("2013-12-31")),
                            nrow(londonPfun("2014-12-31")),nrow(londonPfun("2015-12-31")),
                            nrow(londonPfun("2016-12-31")),nrow(londonPfun("2017-12-31")),
                            nrow(londonPfun("2018-12-31")),nrow(londonPfun("2019-12-31")),
                            nrow(londonPfun("2020-12-31"))))
```

```{r}
ggplot(data = trend, mapping = aes(x = date, y = count, group = 1)) +
  geom_line(alpha = 0.7)+
  geom_point(alpha = 0.6)+
  geom_text(aes(label = count), vjust = "inward", hjust = "outward", size=3.5)+
  xlab("Year")+
  ylab("Number of charging points")+
  ggtitle("Trend of charging infrastructure deployment in London")+
  theme(axis.title = element_text(size=18),axis.text = element_text(size=16),
        strip.text = element_text(size=18))+
  labs(color = "Development trend")+
  theme_classic() 
```
```{r}
ggsave("pic/charge points trend.jpg", width = 7, height = 4)
```

```{r}
londonpoints2018 <- londonPfun("2018-12-31")
londonpoints2019 <- londonPfun("2019-12-31")
londonpoints2020 <- londonPfun("2020-12-31")
```

### Function to map charge point density by wards


```{r}
pointsjoinedfun <- function(londonpointsyear){
  londonpointsyear <- londonpointsyear
  charge_points_ward <- londonpointsyear[londonwards,]
  
  points_wards <- londonwards%>%
    st_join(charge_points_ward)%>%
    add_count(NAME)%>%
    janitor::clean_names()%>%
    #then density of the points per ward
    mutate(density=(n/hectares)*1000) %>% 
    mutate(id=1) %>% 
    mutate(sumpoints=aggregate(n~id,.,FUN=sum)) %>% 
    mutate(percentage=((n/sumpoints[1, 2]))*100) %>% 
    #select density and other variables 
    dplyr::select(density, percentage, name, gss_code, n) %>% 
    distinct(., gss_code, .keep_all = TRUE)
  
  points_wards <- points_wards %>%                    
    group_by(gss_code) %>%         
    summarise(density=density,
              percentage=percentage,
              wardname=name,
              chargepointcount=n)
  return(points_wards)
}
```

### Save charge points by wards

```{r}
points_wards <- pointsjoinedfun(londonpoints2020) %>% 
  st_drop_geometry()
write.table(points_wards,"created datasets/points_wards.csv",row.names=FALSE,col.names=TRUE,sep=",")
```


```{r}
densityfun <- function(londonpointsyear, number, mode){
  points_wards <- pointsjoinedfun(londonpointsyear)
  tmap_mode(mode)
  breaks = c(0, 20, 30, 40, 50, 60, 200, 400, +Inf) 
  tm <- tm_shape(points_wards) +
    tm_polygons("density",
                breaks=breaks,
                palette=RColorBrewer::brewer.pal(8, "YlOrRd"),
                midpoint=NA) +
    tm_legend(show=FALSE)+
    tm_layout(frame=FALSE)+
    tm_credits(number, position=c(0,0.85), size=1)
  
  return(tm)
}

```
```{r}
legendfun <- function(londonpointsyear){
  points_wards <- pointsjoinedfun(londonpointsyear)
  
  breaks = c(0, 20, 30, 40, 50, 60, 200, 400, +Inf) 
  legend <- tm_shape(points_wards) +
    tm_polygons("density",
                breaks=breaks,
                palette=RColorBrewer::brewer.pal(8, "YlOrRd"), 
                title="Density of Charge Points in London \n(per thousand hectare)") +
    tm_scale_bar(position=c(0.4, 0.01), text.size=0.6)+
    tm_compass(north=0, position=c(0.75, 0.3))+
   
    tm_layout(title = "Charge Points Density Trend", 
              legend.title.size=1,
              legend.text.size = 0.6,
              legend.only = TRUE, 
              legend.position=c(0.1,0.1),asp=0.1)
  
  return(legend)
}
```


### Tmap - charge point density by ward

```{r}

tm1 <- densityfun(londonpoints2018, "a)", "plot")
tm2 <- densityfun(londonpoints2019, "b)", "plot")
tm3 <- densityfun(londonpoints2020, "c)", "plot")
```


```{r}
legend <- legendfun(londonpoints2020)


t_density <- tmap_arrange(tm1, tm2, tm3, legend, ncol=2)
t_density
```
```{r}
tmap_save(t_density, 'pic/london charge points density.png', width=7, height=4)
```

```{r}

tm1v <- densityfun(londonpoints2018, "a)", "view")
tm2v <- densityfun(londonpoints2019, "b)", "view")
tm3v <- densityfun(londonpoints2020, "c)", "view")
```


```{r}
legend <- legendfun(londonpoints2020)


t_densityv <- tmap_arrange(tm1v, tm2v, tm3v, ncol=1)
t_densityv
```


<!--chapter:end:02-descriptive-analysis.Rmd-->

# Spatial Autocorrelation Analysis

Considering the spatial lags of variables, variables in neighboring geographical units could be calculated, following the first order queen contiguity strategy, which classifies neighbors of geographical units by the sharing of either point or line segment borders. Followed by that, Global Moran’s I and Local Moran’s I statistics for charge points in London could be conducted. 


## Run Global Moran's I

### Function to calculate the centroids

```{r}
# library(spdep)
# First calculate the centroids of all Wards in London

coordsWfun <- function(londonpointsyear){
  points_wards <- pointsjoinedfun(londonpointsyear)
  coordsW <- points_wards %>% 
    st_centroid() %>%
    st_geometry()
}

```
```{r}
# test
coordsW <- coordsWfun(londonpoints2020)
plot(coordsW,axes=TRUE)
```


### Function to create a neighbours list

```{r}
#create a neighbours list
ward_nbfun <- function(londonpointsyear){
  points_wards <- pointsjoinedfun(londonpointsyear)
  ward_nb <- points_wards %>% 
    poly2nb(., queen=T)
  return(ward_nb)
}

```
```{r}
# test
ward_nb20 <- ward_nbfun(londonpoints2020)
plot(ward_nb20, st_geometry(coordsW), col="red")
# add a map underneath
points_wards <- pointsjoinedfun(londonpoints2020) 
plot(points_wards$geometry, add=T)
```

### Function to create spatial weights

```{r}
#create a spatial weights object from these weights
ward_lwfun <- function(londonpointsyear){
  ward_lw <- ward_nbfun(londonpointsyear) %>% 
    nb2listw(., style="C")
  return(ward_lw)
}
```
```{r}
# test
ward_lw20 <- ward_lwfun(londonpoints2020)
head(ward_lw20$neighbours)
```


### Function to run Global Moran's I

```{r}
I_ward_globalfun <- function(londonpointsyear){
  ward_lw <- ward_lwfun(londonpointsyear)
  
  I_ward_global <- londonpointsyear %>% 
    pointsjoinedfun(.) %>% 
    pull(density) %>%
    as.vector()%>% # Converts a distributed matrix into a non-distributed vector
    moran.test(., ward_lw) # density <-> spatial (similar or not)
  return(I_ward_global)
}

```


### Global Moran's I for 2018, 2019, 2020

```{r}
I_ward_global18 <- I_ward_globalfun(londonpoints2018)
I_ward_global19 <- I_ward_globalfun(londonpoints2019)
I_ward_global20 <- I_ward_globalfun(londonpoints2020)

```
```{r}
I_ward_global18
I_ward_global19
I_ward_global20

```


## Run Local Moran's I

### Function to run Local Moran's I

```{r}
ward_lw20 <- ward_lwfun(londonpoints2020)
  
  I_ward_local_count <- londonpoints2020 %>% 
    pointsjoinedfun(.) %>% 
    pull(chargepointcount) %>%
    as.vector()%>% 
    localmoran(., ward_lw20) %>% 
    as_tibble()
  I_ward_local_density <- londonpoints2020 %>% 
    pointsjoinedfun(.) %>% 
    pull(density) %>%
    as.vector()%>% 
    localmoran(., ward_lw20) %>% 
    as_tibble()

slice_head(I_ward_local_count, n=5)
slice_head(I_ward_local_density, n=5)
```


```{r}
# use the local moran function to generate I for each ward in the city

I_ward_localfun <- function(londonpointsyear){
  ward_lw <- ward_lwfun(londonpointsyear)
  
  I_ward_local_count <- londonpointsyear %>% 
    pointsjoinedfun(.) %>% 
    pull(chargepointcount) %>%
    as.vector()%>% 
    localmoran(., ward_lw) %>% 
    as_tibble()
  I_ward_local_density <- londonpointsyear %>% 
    pointsjoinedfun(.) %>% 
    pull(density) %>%
    as.vector()%>% 
    localmoran(., ward_lw) %>% 
    as_tibble()
  
  tm_local_moran <- londonpointsyear %>% 
    pointsjoinedfun(.) %>%
    mutate(charge_count_I = as.numeric(I_ward_local_count$Ii))%>%
    mutate(charge_count_Iz =as.numeric(I_ward_local_count$Z.Ii))%>%
    mutate(density_I =as.numeric(I_ward_local_density$Ii))%>%
    mutate(density_Iz =as.numeric(I_ward_local_density$Z.Ii))
  
  return(tm_local_moran)
}

```


### Function to run tmap for Local Moran's I

```{r}
tmap_local_moranfun <- function(londonpointsyear, number, mode){
  breaks1<-c(-1000,-2.58,-1.96,-1.65,1.65,1.96,2.58,1000)
  MoranColours<- rev(brewer.pal(8, "RdBu"))
  tm_local_moran <- I_ward_localfun(londonpointsyear)
  tmap_mode(mode)
  tmap <- tm_shape(tm_local_moran) +
    tm_polygons("charge_count_Iz",
        style="fixed",
        breaks=breaks1,
        palette=MoranColours,
        midpoint=NA)+
    tm_legend(show=FALSE)+
    tm_layout(frame=FALSE)+
    tm_credits(number, position=c(0,0.85), size=1)
  return(tmap)
}
```
```{r}
tmap_moranlegendfun <- function(londonpointsyear){
  breaks1<-c(-1000,-2.58,-1.96,-1.65,1.65,1.96,2.58,1000)
  MoranColours<- rev(brewer.pal(8, "RdBu"))
  tm_local_moran <- I_ward_localfun(londonpointsyear)
  legend <- tm_shape(tm_local_moran) +
    tm_polygons("charge_count_Iz",
                breaks=breaks1,
                palette=MoranColours,
                title="Local Moran's I, Charge Points in London") +
    tm_scale_bar(position=c(0.1,0.04), text.size=0.6)+
    tm_compass(north=0, position=c(0.65,0.2))+
   
    tm_layout(title = "Charge Points Local Moran's I", 
              legend.title.size=1,
              legend.text.size = 0.6,
              legend.only = TRUE, 
              legend.position=c(0.1,0.25),asp=0.1)
  
  return(legend)
}
```


```{r}
tm_local_moran18 <- tmap_local_moranfun(londonpoints2018, "a)", "plot")
tm_local_moran19 <- tmap_local_moranfun(londonpoints2019, "b)", "plot")
tm_local_moran20 <- tmap_local_moranfun(londonpoints2020, "c)", "plot")
```
```{r}
moran_legend <- tmap_moranlegendfun(londonpoints2020)

local_moran <- tmap_arrange(tm_local_moran18, 
                            tm_local_moran19, 
                            tm_local_moran20, 
                            moran_legend, ncol=2)
local_moran
```

```{r}
tmap_save(local_moran, "pic/Local Moran's I, Charge Points in London.png",width=7, height=4)
```
```{r}
tm_local_moran18v <- tmap_local_moranfun(londonpoints2018, "a)", "view")
tm_local_moran19v <- tmap_local_moranfun(londonpoints2019, "b)", "view")
tm_local_moran20v <- tmap_local_moranfun(londonpoints2020, "c)", "view")
```
```{r}
moran_legend <- tmap_moranlegendfun(londonpoints2020)

local_moran <- tmap_arrange(tm_local_moran18v, 
                            tm_local_moran19v, 
                            tm_local_moran20v, ncol=1)
local_moran
```


### Function to run Gi*

```{r}
Gi_ward_local_densityfun <- function(londonpointsyear){
  ward_lw <- ward_lwfun(londonpointsyear)
  
  Gi_ward_local_density <- londonpointsyear %>% 
    pointsjoinedfun(.) %>% 
    pull(density) %>%
    as.vector()%>%
    localG(., ward_lw)
  
  density_Gi <- londonpointsyear %>% 
    pointsjoinedfun(.) %>% 
    mutate(density_G = as.numeric(Gi_ward_local_density))
  
  return(density_Gi)
}
```


### Function to run tmap for Gi*

```{r}
tmap_Gifun <- function(londonpointsyear, number, mode){
  breaks1<-c(-1000,-2.58,-1.96,-1.65,1.65,1.96,2.58,1000)
  GIColours<- rev(brewer.pal(8, "RdBu"))
  density_Gi <- Gi_ward_local_densityfun(londonpointsyear)
  tmap_mode(mode)
  tmap <- tm_shape(density_Gi) +
    tm_polygons("density_G",
                breaks=breaks1,
                palette=GIColours,
                title="Gi*, Charge Points in London") +
    tm_legend(show=FALSE)+
    tm_layout(frame=FALSE)+
    tm_credits(number, position=c(0,0.85), size=1)
  
  return(tmap)
}
```

```{r}
G1 <- tmap_Gifun(londonpoints2018, "a)", "plot")
G2 <- tmap_Gifun(londonpoints2019, "b)", "plot")
G3 <- tmap_Gifun(londonpoints2020, "c)", "plot")
```

```{r}
tmap_Gilegendfun <- function(londonpointsyear){
  breaks1<-c(-1000,-2.58,-1.96,-1.65,1.65,1.96,2.58,1000)
  GIColours<- rev(brewer.pal(8, "RdBu"))
  density_Gi <- Gi_ward_local_densityfun(londonpointsyear)
  legend <- tm_shape(density_Gi) +
    tm_polygons("density_G",
                breaks=breaks1,
                palette=GIColours,
                title="Gi*, Charge Points in London") +
    tm_scale_bar(position=c(0.1,0.04), text.size=0.6)+
    tm_compass(north=0, position=c(0.65,0.2))+
   
    tm_layout(title = "Charge Points Gi* Density", 
              legend.title.size=1,
              legend.text.size = 0.6,
              legend.only = TRUE, 
              legend.position=c(0.1,0.25),asp=0.1)
  
  return(legend)
}
```
```{r}
Gi_legend <- tmap_Gilegendfun(londonpoints2020)

Gi <- tmap_arrange(G1, G2, G3, Gi_legend, ncol=2)
Gi
```
```{r}
tmap_save(local_moran, "pic/Gi, Charge Points in London.png",width=7, height=4)
```

<!--chapter:end:03-spatial-autocorrelation.Rmd-->


# Statistical Correlation Analysis

There are several characteristics are considered to contribute to the density of charge points (CD) and its utilization rates (UR), including socio-demographic, travel-related and land-use characteristics. In specific, they are employment rate (ER), house price (HP), public transit score (PS), which could reflect the level of local public transport), parking density (PD), percentage of residential area (RSP) and percentage of road area (RP). 

## Load packages


### Load plot library

```{r}
library(Rmisc) 
library(plyr)
```

### Load model library

```{r}
library(stats)
library(corrr)
library(car)
library(spatstat)
library(tidymodels)
library(spatialreg)
```

## Load files

### Load London wards shapefile

```{r}
londonwards <- st_read("datasets/wards/London_Ward_CityMerged.shp") %>% 
  st_transform(., 27700)
```


### Load points in wards

```{r}
points_wards <- read_csv("created datasets/points_wards.csv")
summary(points_wards)
```



### Load wards profile

Load London wards profile as the basic data frame for correlation analysis

```{r}
ward_profile <- read_csv("datasets/ward_profiles.csv",
                         col_types = cols(
                           "New code" = col_character(),
                           "% All Working-age (16-64) - 2015"= col_number(),
                           "Population density (persons per sq km) - 2013"= col_number(),
                           "Number Killed or Seriously Injured on the roads - 2014" = col_number(),
                           "Employment rate (16-64) - 2011" = col_number(),
                           "Median House Price (£) - 2014" = col_number(),
                           "Cars per household - 2011" = col_number(),
                           "Average Public Transport Accessibility score - 2014"= col_number()
                         ))
colnames(ward_profile)
head(ward_profile)
```

```{r}
londonward_code <- londonwards %>% 
  st_drop_geometry() %>% 
  clean_names() 
```
```{r}
londonward_code <- londonward_code %>% 
  dplyr::select(., c(2))
```

```{r}
wardprofile <- ward_profile %>% 
  dplyr::select(., c(1, 2, 3, 9, 14, 25, 27, 31, 64, 65)) %>% 
  clean_names() %>% 
  group_by(ward_name) %>%         
    summarise(old_code=old_code,
              gss_code=new_code,
              pop_density=population_density_persons_per_sq_km_2013,
              road_incidents=number_killed_or_seriously_injured_on_the_roads_2014,
              employment_rate=employment_rate_16_64_2011,
              houseprice=median_house_price_2014,
              car_ownership=cars_per_household_2011,
              publictransaccess_score=average_public_transport_accessibility_score_2014)%>% 
  merge(londonward_code, .,
        by.x = "gss_code",
        by.y = "gss_code") %>% 
  distinct(.,.keep_all=TRUE)


colnames(wardprofile)
```
```{r}
write.table(wardprofile,"created datasets/wardprofile.csv",row.names=FALSE,col.names=TRUE,sep=",")
```
```{r}
allcharacter <- points_wards %>% 
  left_join(wardprofile,.,
            by = c("gss_code" = "gss_code"))
```


### Load household.csv

```{r}
household <- read_csv("datasets/households-type-2001-ward.csv") %>% 
  dplyr::select(., c(1, 3)) %>% 
  clean_names()
summary(household)
```

Join household dataset to the ward profile data frame

```{r}
allcharacter <- allcharacter %>% 
  left_join(., household,
            by = c("old_code" = "area_code"))
```



### Load land use.csv

```{r}
landuse <- read_csv("datasets/land-use-glud-ward.csv") %>% 
  dplyr::select(., c(1, 3, 16, 17, 19, 20, 21)) %>% 
  clean_names() %>% 
  group_by(area_name) %>%         
    summarise(area_code=area_code,
              residential_percentage=percent_area_of_domestic_buildings+percent_area_of_domestic_gardens, road_percentage= percent_area_of_road,
              rail_percentage = percent_area_of_rail,
              path_percentage = percent_area_of_path)
              
              
summary(landuse)
```

Join landuse dataset to the ward profile data frame

```{r}
allcharacter <- allcharacter %>% 
  left_join(., landuse,
            by = c("old_code" = "area_code"))
```

### Load parking.shp

```{r}
parking <- st_read("datasets/parking/gis_osm_traffic_a_free_1.shp") %>% 
  st_transform(., 27700) 
```

Join parking dataset to the ward profile data frame

```{r}
parking <- parking[parking$fclass=="parking"|parking$fclass=="parking_multistorey"|parking$fclass=="parking_underground"|parking$fclass=="parking_site",] 

parking_london <- st_intersects(londonwards, parking)
londonparking <- parking[unlist(parking_london),]
```
```{r}
parking_ward <- londonparking[londonwards,]
parking_wards <- londonwards%>%
    st_join(parking_ward)%>%
    add_count(NAME)%>%
    janitor::clean_names() %>% 
  mutate(parking_density=(n/hectares)*1000) %>% 
  dplyr::select(gss_code, parking_density) %>% 
  distinct(., gss_code, .keep_all = TRUE)
```
```{r}
allcharacter <- allcharacter %>% 
  left_join(., parking_wards,
            by = c("gss_code" = "gss_code")) 
```

### Select independent variables

```{r}
colnames(allcharacter)
```
```{r}
allcharacter <- allcharacter %>%                    
    dplyr::select(., c(1, 9, 12, 3, 5, 6, 7, 13, 8, 18, 4, 14, 15, 16, 17))
```

```{r}
characters <- allcharacter %>% 
  mutate(userate=(car_ownership*all_households)/chargepointcount) %>% 
  dplyr::select(., c(1,2,16,4,5,6,9,10,11,12,13,14,15))
```
```{r}
colnames(characters)
```

### Save all characters.csv

```{r}
write.table(points_wards,"created datasets/characters.csv",row.names=FALSE,col.names=TRUE,sep=",")
```


## Check variable distributions

Ensure the variables could be normal distribution

### Variables

```{r}
p1 <- ggplot(data=characters, aes(x=density))+
  geom_histogram()
p2 <- ggplot(data=characters, aes(x=userate))+
  geom_histogram()
p3 <- ggplot(data=characters, aes(x=pop_density))+
  geom_histogram()
p4 <- ggplot(data=characters, aes(x=employment_rate))+
  geom_histogram()
p5 <- ggplot(data=characters, aes(x=houseprice))+
  geom_histogram()
p6 <- ggplot(data=characters, aes(x=publictransaccess_score))+
  geom_histogram()
p7 <- ggplot(data=characters, aes(x=parking_density))+
  geom_histogram()
p8 <- ggplot(data=characters, aes(x=road_incidents))+
  geom_histogram()
p9 <- ggplot(data=characters, aes(x=residential_percentage))+
  geom_histogram()
p10 <- ggplot(data=characters, aes(x=road_percentage))+
  geom_histogram()
p11 <- ggplot(data=characters, aes(x=rail_percentage))+
  geom_histogram()
p12 <- ggplot(data=characters, aes(x=path_percentage))+
  geom_histogram()
```


### Plot variable distribution

```{r}
multiplot(p1, p2, p3, p4, p5, p6, p7, p8, p9, p10, p11, p12, cols = 3)
```

### Plot log(variable) distribution

```{r}
lp1 <- ggplot(data=characters, aes(x=log(density)))+
  geom_histogram()
lp2 <- ggplot(data=characters, aes(x=log(userate)))+
  geom_histogram()
lp3 <- ggplot(data=characters, aes(x=log(pop_density)))+
  geom_histogram()
lp4 <- ggplot(data=characters, aes(x=log(employment_rate)))+
  geom_histogram()
lp5 <- ggplot(data=characters, aes(x=log(houseprice)))+
  geom_histogram()
lp6 <- ggplot(data=characters, aes(x=log(publictransaccess_score)))+
  geom_histogram()
lp7 <- ggplot(data=characters, aes(x=log(parking_density)))+
  geom_histogram()
lp8 <- ggplot(data=characters, aes(x=log(road_incidents)))+
  geom_histogram()
lp9 <- ggplot(data=characters, aes(x=log(residential_percentage)))+
  geom_histogram()
lp10 <- ggplot(data=characters, aes(x=log(road_percentage)))+
  geom_histogram()
lp11 <- ggplot(data=characters, aes(x=log(rail_percentage)))+
  geom_histogram()
lp12 <- ggplot(data=characters, aes(x=log(path_percentage)))+
  geom_histogram()
```


### Plot log(variable) distribution

```{r}
multiplot(lp1, lp2, lp3, lp4, lp5, lp6, lp7, lp8, lp9, lp10, lp11, lp12, cols = 3)
```

### Plot normal distribution


```{r}
multiplot(lp1, lp2, p3, p4, lp5, lp6, lp7, p9, p10, cols = 3)
```

### Independent variables

```{r}
independent <- characters %>% 
  dplyr::select(., c(1, 2, 3, 5, 6, 7, 8, 10, 11))
```
```{r}
colnames(independent)
```


## Correlation analysis

### Correlationship of userate & public transit of charge points in London

Remove possible outliers and plot the correlationship between these variables, comparing the charging density case and use rate case and finding the overall relationship. 

```{r}
qu1 <- qplot(x = `employment_rate`, 
             y = `userate`, 
             data=independent, 
             xlim = c(50, 85))

#plot with a regression line
qu1 <- qu1 + stat_smooth(method="lm", se=FALSE, size=1)
qd1 <- qplot(x = `employment_rate`, 
             y = `density`, 
             data=independent, 
             xlim = c(50, 85))

#plot with a regression line
qd1 <- qd1 + stat_smooth(method="lm", se=FALSE, size=1)
multiplot(qd1, qu1, cols = 2)
```
```{r}
qu2 <- qplot(x = `houseprice`, 
             y = `userate`, 
             data=independent, 
             xlim = c(250000, 800000))

#plot with a regression line
qu2 <- qu2 + stat_smooth(method="lm", se=FALSE, size=1) 
qd2 <- qplot(x = `houseprice`, 
             y = `density`,
             data=independent,
             xlim = c(250000, 800000))

#plot with a regression line
qd2 <- qd2 + stat_smooth(method="lm", se=FALSE, size=1) 
multiplot(qd2, qu2, cols = 2)
```
```{r}
qu3 <- qplot(x = `publictransaccess_score`, 
             y = `userate`, 
             data=independent)

#plot with a regression line
qu3 <- qu3 + stat_smooth(method="lm", se=FALSE, size=1) 
qd3 <- qplot(x = `publictransaccess_score`, 
             y = `density`, 
             data=independent)

#plot with a regression line
qd3 <- qd3 + stat_smooth(method="lm", se=FALSE, size=1)
multiplot(qd3, qu3, cols = 2)
```
```{r}
qu4 <- qplot(x = `parking_density`, 
             y = `userate`, 
             data=independent,
             xlim = c(0, 500))

#plot with a regression line
qu4 <- qu4 + stat_smooth(method="lm", se=FALSE, size=1)
qd4 <- qplot(x = `parking_density`, 
             y = `density`, 
             data=independent,
             xlim = c(0, 500))

#plot with a regression line
qd4 <- qd4 + stat_smooth(method="lm", se=FALSE, size=1)
multiplot(qd4, qu4, cols = 2)
```
```{r}
qu5 <- qplot(x = `residential_percentage`, 
             y = `userate`, 
             data=independent)

#plot with a regression line
qu5 <- qu5 + stat_smooth(method="lm", se=FALSE, size=1)
qd5 <- qplot(x = `residential_percentage`, 
             y = `density`, 
             data=independent)

#plot with a regression line
qd5 <- qd5 + stat_smooth(method="lm", se=FALSE, size=1)
multiplot(qd5, qu5, cols = 2)
```
```{r}
qu6 <- qplot(x = `road_percentage`, 
             y = `userate`, 
             data=independent)

#plot with a regression line
qu6 <- qu6 + stat_smooth(method="lm", se=FALSE, size=1)
qd6 <- qplot(x = `road_percentage`, 
             y = `density`, 
             data=independent)

#plot with a regression line
qd6 <- qd6 + stat_smooth(method="lm", se=FALSE, size=1)
multiplot(qd6, qu6, cols = 2)
```





<!--chapter:end:04-correlation-analysis.Rmd-->



# Regression Analysis

In order to forecast charging facility location selection for future, the following part will compare the charge points registration distribution with other characteristics mentioned above, including land-use, travel-related and socio-demographic characteristics, applying ordinary least squares (OLS) regression models. In order to achieve higher accuracy for the results, Spatial Lag Model (SLM) which involves a separate spatially lagged variant of the dependent variable as an independent variable of the model, as well as Spatial Error Model (SEM) which incorporates a spatial lag of the OLS regression model’s residual as an independent variable, all participate in the comparison.

## Ordinary Least Squares (OLS) regression model

Find the specific relationship between those different variables

```{r}
# regression model
model1 <- lm(log(userate) ~
               employment_rate+
               log(houseprice)+
               log(publictransaccess_score)+
               log(parking_density)+
               residential_percentage+
               road_percentage, 
             data = independent)
```
```{r}
#show the summary of those outputs
summary(model1)
glance(model1)
```
```{r}
m1_tidy <- model1 %>% 
  tidy() 
m1_tidy
```
```{r}
# regression model
model2 <- lm(log(density) ~ 
               employment_rate+
               log(houseprice)+
               log(publictransaccess_score)+
               log(parking_density)+
               residential_percentage+
               road_percentage, 
             data = characters)
```
```{r}
#show the summary of those outputs
summary(model2)
glance(model2)
```

## Assumptions Underpinning Linear Regression

### Assumption 1 - There is a linear relationship between the dependent and independent variables

```{r}
multiplot(lp1, lp2, p4, lp5, lp6, lp7, p9, p10, cols = 3)
```

### Assumption 2 - The residuals in your model should be normally distributed

```{r}
#save the residuals into dataframe

model1_data <- model1 %>%
  augment(., independent)

#plot residuals
model1_data%>%
dplyr::select(.resid)%>%
  pull()%>%
  qplot()+ 
  geom_histogram() 
```
```{r}
#save the residuals into dataframe

model2_data <- model2 %>%
  augment(., independent)

#plot residuals
model2_data%>%
dplyr::select(.resid)%>%
  pull()%>%
  qplot()+ 
  geom_histogram() 
```


### Assumption 3 - No Multicolinearity in the independent variables

```{r}
position <- c(2:9)

Correlation_all<- independent %>%
  dplyr::select(position)%>%
    correlate()
Correlation_all
```
```{r}
position <- c(4:9)

Correlation<- independent %>%
  dplyr::select(position)%>%
  dplyr::rename(ER="employment_rate",
         HP="houseprice",
         PS="publictransaccess_score",
         PD="parking_density",
         RSP="residential_percentage",
         RP="road_percentage"
         ) %>% 
    correlate()
r <- rplot(Correlation, shape = 15,colours = c("skyblue1", "white", "indianred2"))
r
```
```{r}
png(filename = "pic/correlation.png", 
    width = 500, height = 500)     
r
dev.off()
```


### Assumption 4 - Homoscedasticity

```{r}
par(mfrow=c(2,2)) 
plot(model1)
```
```{r}
par(mfrow=c(2,2)) 
plot(model2)
```

### Assumption 5 - Independence of Errors

```{r}
#run durbin-watson test m1
DW1 <- durbinWatsonTest(model1)
tidy(DW1)
```

```{r}
#run durbin-watson test m2
DW2 <- durbinWatsonTest(model2)
tidy(DW2)
```

```{r}
residuals <- londonwards %>% 
  mutate(model1residual = residuals(model1)) %>% 
  mutate(model2residual = residuals(model2))
```

```{r}
#plot the residuals m1
tmap_mode("view")
qtm(residuals, fill = "model1residual")

```
```{r}
#plot the residuals m2
tmap_mode("view")
qtm(residuals, fill = "model2residual")
```

### Moran's I test for residuals (generally)

```{r}
coordsW <- residuals %>% 
    st_centroid() %>%
    st_geometry()
```
```{r}
# queen
queen_nb <- residuals %>%
  poly2nb(., queen=T)

# k nearest neighbours
knn_nb <-coordsW %>%
  knearneigh(., k=9)%>%
  knn2nb()
```

```{r}
#create spatial weights matrix 

queens_weight <- queen_nb %>%
  nb2listw(., style="C")

knn_weight <- knn_nb %>%
  nb2listw(., style="C")
```

```{r}
Queen1 <- residuals %>%
  st_drop_geometry()%>%
  dplyr::select(model1residual)%>%
  pull()%>%
  moran.test(., queens_weight)%>%
  tidy()
Queen1
```

```{r}
Knn1 <- residuals %>%
  st_drop_geometry()%>%
  dplyr::select(model1residual)%>%
  pull()%>%
  moran.test(., knn_weight)%>%
  tidy()
Knn1
```

```{r}
Queen2 <- residuals %>%
  st_drop_geometry()%>%
  dplyr::select(model2residual)%>%
  pull()%>%
  moran.test(., queens_weight)%>%
  tidy()
Queen2
```

```{r}
Knn2 <- residuals %>%
  st_drop_geometry()%>%
  dplyr::select(model2residual)%>%
  pull()%>%
  moran.test(., knn_weight)%>%
  tidy()
Knn2
```

## Spatial Regression Models

### Spatial Lag models for Model 1 (queen)


```{r}
lag_model1_queen <- lagsarlm(log(userate) ~
                               employment_rate+
                               log(houseprice)+
                               log(publictransaccess_score)+
                               log(parking_density)+
                               residential_percentage+
                               road_percentage,
                             data = independent, 
                             nb2listw(queen_nb, style="C"), 
                             method = "eigen")

tidy(lag_model1_queen)
glance(lag_model1_queen)
```

### Spatial Lag models for Model 2 (queen)

```{r}
lag_model2_queen <- lagsarlm(log(density) ~
                               employment_rate+
                               log(houseprice)+
                               log(publictransaccess_score)+
                               log(parking_density)+
                               residential_percentage+
                               road_percentage,
                             data = independent, 
                             nb2listw(queen_nb, style="C"), 
                             method = "eigen")

tidy(lag_model2_queen)
glance(lag_model2_queen)
```

### Spatial Error models for Model 1 (queen)

```{r}
error_model1_queen <- errorsarlm(log(userate) ~
                                   employment_rate+
                                   log(houseprice)+
                                   log(publictransaccess_score)+
                                   log(parking_density)+
                                   residential_percentage+
                                   road_percentage,
                                 data = independent, 
                                 nb2listw(queen_nb, style="C"), 
                                 method = "eigen")

tidy(error_model1_queen)
glance(error_model1_queen)
```

### Spatial Error models for Model 2 (queen)

```{r}
error_model2_queen <- errorsarlm(log(density) ~
                                   employment_rate+
                                   log(houseprice)+
                                   log(publictransaccess_score)+
                                   log(parking_density)+
                                   residential_percentage+
                                   road_percentage,
                                 data = independent, 
                                 nb2listw(queen_nb, style="C"), 
                                 method = "eigen")

tidy(error_model2_queen)
glance(error_model2_queen)
```



### Find best k for KNN strategy

Use for loop to find the best k (1 to 10) for those Spatial Regression Models, and summarize the best k values, corresponding R-squared and AIC, so that they can be compared and the better results can be identified for further analysis.

#### The k for Spatial Lag Model 1


```{r}
r_squared <- list()
best_k <- list()
AIC <- list()
# create empty variable to store fit
k <- NA
a <- NA
  
# run the k-means 10 times
for (i in 1:10){
  
  # keep track of the runs
  print(paste0('starting run: k = ', i))
  coordsW <- residuals %>% 
    st_centroid() %>%
    st_geometry()
  knn_nb <-coordsW %>%
  knearneigh(., k=i)%>%
  knn2nb()
  
  knn_weight <- knn_nb %>%
  nb2listw(., style="C")
  
  lag_model1_knni <- lagsarlm(log(userate) ~
                              employment_rate+
                              log(houseprice)+
                              log(publictransaccess_score)+
                              log(parking_density)+
                              residential_percentage+
                              road_percentage,
                            data = independent, 
                            nb2listw(knn_nb, style="C"), 
                            method = "eigen")

  k[i] <- glance(lag_model1_knni)[[1]]
  a[i] <- glance(lag_model1_knni)[[2]]
  
  # update the results of the clustering if the total within sum of squares for the run
  # is lower than any of the runs that have been executed so far 
  if (k[i] > max (k[1:(i-1)])){
    r_squared <- k[i]
    best_k <- i
    AIC <- a[i]}
}

```
```{r}
r_squared 
best_k 
AIC
```

#### The k for Spatial Lag Model 2

```{r}
r_squared2 <- list()
best_k2 <- list()
AIC2 <- list()
# create empty variable to store fit
k <- NA
a <- NA
  
# run the k-means 10 times
for (i in 1:10){
  
  # keep track of the runs
  print(paste0('starting run: k = ', i))
  coordsW <- residuals %>% 
    st_centroid() %>%
    st_geometry()
  knn_nb <-coordsW %>%
  knearneigh(., k=i)%>%
  knn2nb()
  
  knn_weight <- knn_nb %>%
  nb2listw(., style="C")
  
  lag_model2_knni <- lagsarlm(log(density) ~
                              employment_rate+
                              log(houseprice)+
                              log(publictransaccess_score)+
                              log(parking_density)+
                              residential_percentage+
                              road_percentage,
                            data = independent, 
                            nb2listw(knn_nb, style="C"), 
                            method = "eigen")

  k[i] <- glance(lag_model2_knni)[[1]]
  a[i] <- glance(lag_model2_knni)[[2]]
  
  # update the results of the clustering if the total within sum of squares for the run
  # is lower than any of the runs that have been executed so far 
  if (k[i] > max (k[1:(i-1)])){
    r_squared2 <- k[i]
    best_k2 <- i
    AIC2 <- a[i]}
}

```
```{r}
r_squared2
best_k2 
AIC2
```


#### The k for Spatial Error Model 1


```{r}
r_squared3 <- list()
best_k3 <- list()
AIC3 <- list()
# create empty variable to store fit
k <- NA
a <- NA
  
# run the k-means 10 times
for (i in 1:10){
  
  # keep track of the runs
  print(paste0('starting run: k = ', i))
  coordsW <- residuals %>% 
    st_centroid() %>%
    st_geometry()
  knn_nb <-coordsW %>%
  knearneigh(., k=i)%>%
  knn2nb()
  
  knn_weight <- knn_nb %>%
  nb2listw(., style="C")
  
  error_model1_knni <- errorsarlm(log(userate) ~
                                  employment_rate+
                                  log(houseprice)+
                                  log(publictransaccess_score)+
                                  log(parking_density)+
                                  residential_percentage+
                                  road_percentage,
                                data = independent, 
                                nb2listw(knn_nb, style="C"), 
                                method = "eigen")

  k[i] <- glance(error_model1_knni)[[1]]
  a[i] <- glance(error_model1_knni)[[2]]
  
  # update the results of the clustering if the total within sum of squares for the run
  # is lower than any of the runs that have been executed so far 
  if (k[i] > max (k[1:(i-1)])){
    r_squared3 <- k[i]
    best_k3 <- i
    AIC3 <- a[i]}
}

```
```{r}
r_squared3
best_k3 
AIC3
```

#### The k for Spatial Error Model 2

```{r}
r_squared4 <- list()
best_k4 <- list()
AIC4 <- list()
# create empty variable to store fit
k <- NA
a <- NA
  
# run the k-means 10 times
for (i in 1:10){
  
  # keep track of the runs
  print(paste0('starting run: k = ', i))
  coordsW <- residuals %>% 
    st_centroid() %>%
    st_geometry()
  knn_nb <-coordsW %>%
  knearneigh(., k=i)%>%
  knn2nb()
  
  knn_weight <- knn_nb %>%
  nb2listw(., style="C")
  
  error_model2_knni <- errorsarlm(log(density) ~
                                  employment_rate+
                                  log(houseprice)+
                                  log(publictransaccess_score)+
                                  log(parking_density)+
                                  residential_percentage+
                                  road_percentage,
                                data = independent, 
                                nb2listw(knn_nb, style="C"), 
                                method = "eigen")

  k[i] <- glance(error_model2_knni)[[1]]
  a[i] <- glance(error_model2_knni)[[2]]
  
  # update the results of the clustering if the total within sum of squares for the run
  # is lower than any of the runs that have been executed so far 
  if (k[i] > max (k[1:(i-1)])){
    r_squared4 <- k[i]
    best_k4 <- i
    AIC4 <- a[i]}
}

```
```{r}
r_squared4 
best_k4 
AIC4
```


### Spatial Error models for Model 1 (KNN; k=9)


```{r}
error_model1_knn9 <- errorsarlm(log(userate) ~
                                  employment_rate+
                                  log(houseprice)+
                                  log(publictransaccess_score)+
                                  log(parking_density)+
                                  residential_percentage+
                                  road_percentage,
                                data = independent, 
                                nb2listw(knn_nb, style="C"), 
                                method = "eigen")

tidy(error_model1_knn9)
glance(error_model1_knn9)
```
```{r}
error_model2_knn9 <- errorsarlm(log(density) ~
                                  employment_rate+
                                  log(houseprice)+
                                  log(publictransaccess_score)+
                                  log(parking_density)+
                                  residential_percentage+
                                  road_percentage,
                                data = independent, 
                                nb2listw(knn_nb, style="C"), 
                                method = "eigen")

tidy(error_model2_knn9)
glance(error_model2_knn9)
```

#### Check residuals

Check wether the residuals of the better model still show spatial correlation. 

```{r}
# residuals for spatial error model 1

residuals <- residuals %>%
  mutate(error_model1_knn9_resids = residuals(error_model1_knn9))

ErrorMoran1 <- residuals %>%
  st_drop_geometry()%>%
  dplyr::select(error_model1_knn9_resids)%>%
  pull()%>%
  moran.test(., knn_weight)%>%
  tidy()

ErrorMoran1
```

```{r}
# residuals for spatial error model 2

residuals <- residuals %>%
  mutate(error_model2_knn9_resids = residuals(error_model2_knn9))

ErrorMoran2 <- residuals %>%
  st_drop_geometry()%>%
  dplyr::select(error_model2_knn9_resids)%>%
  pull()%>%
  moran.test(., knn_weight)%>%
  tidy()

ErrorMoran2
```


<!--chapter:end:05-regression-analysis.Rmd-->

